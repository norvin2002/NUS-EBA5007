{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import scale\n",
    "import os\n",
    "\n",
    "import codecs\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed value\n",
    "random_seed= 42\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(random_seed)\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(random_seed)\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CTRIAD train\n",
    "\n",
    "ctriad_train_N = pd.read_csv('C:/Users/nchandra/OneDrive - National University of Singapore/FYP/BioStatsFYP/PredProtein/311020 FYP/data/CTRIAD_train_N.csv')\n",
    "\n",
    "ctriad_train_P = pd.read_csv('C:/Users/nchandra/OneDrive - National University of Singapore/FYP/BioStatsFYP/PredProtein/311020 FYP/data/CTRIAD_train_P.csv')\n",
    "\n",
    "\n",
    "ctriad_train = pd.concat([ctriad_train_P.iloc[:,1:], ctriad_train_N.iloc[:,1:]], axis = 0)\n",
    "ctriad_train.reset_index(drop = True, inplace = True)\n",
    "ctriad_train['target'] = ctriad_train['target'].astype('category')\n",
    "\n",
    "#Train test split\n",
    "ctriad_train_class = ctriad_train['target'].values\n",
    "ctriad_X = ctriad_train.drop('target', axis = 1)\n",
    "ctriad_y = ctriad_train['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTRIAD independent test data\n",
    "\n",
    "ctriad_test_N = pd.read_csv('C:/Users/nchandra/OneDrive - National University of Singapore/FYP/BioStatsFYP/PredProtein/311020 FYP/data/CTRIAD_ind_N.csv')\n",
    "\n",
    "ctriad_test_P = pd.read_csv('C:/Users/nchandra/OneDrive - National University of Singapore/FYP/BioStatsFYP/PredProtein/311020 FYP/data/CTRIAD_ind_P.csv')\n",
    "\n",
    "ctriad_test = pd.concat([ctriad_test_P.iloc[:,1:], ctriad_test_N.iloc[:,1:]], axis = 0)\n",
    "ctriad_test.reset_index(drop = True, inplace = True)\n",
    "ctriad_test['target'] = ctriad_test['target'].astype('category')\n",
    "\n",
    "ctriad_indX_test = ctriad_test.drop('target', axis = 1)\n",
    "ctriad_indy_test = ctriad_test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack CTRIAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = minmax.fit_transform(ctriad_X)\n",
    "X = pd.DataFrame(X, index=ctriad_X.index, columns=ctriad_X.columns)\n",
    "y = ctriad_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g1.g1.g1</th>\n",
       "      <th>g1.g1.g2</th>\n",
       "      <th>g1.g1.g3</th>\n",
       "      <th>g1.g1.g4</th>\n",
       "      <th>g1.g1.g5</th>\n",
       "      <th>g1.g1.g6</th>\n",
       "      <th>g1.g1.g7</th>\n",
       "      <th>g1.g2.g1</th>\n",
       "      <th>g1.g2.g2</th>\n",
       "      <th>g1.g2.g3</th>\n",
       "      <th>...</th>\n",
       "      <th>g7.g6.g5</th>\n",
       "      <th>g7.g6.g6</th>\n",
       "      <th>g7.g6.g7</th>\n",
       "      <th>g7.g7.g1</th>\n",
       "      <th>g7.g7.g2</th>\n",
       "      <th>g7.g7.g3</th>\n",
       "      <th>g7.g7.g4</th>\n",
       "      <th>g7.g7.g5</th>\n",
       "      <th>g7.g7.g6</th>\n",
       "      <th>g7.g7.g7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   g1.g1.g1  g1.g1.g2  g1.g1.g3  g1.g1.g4  g1.g1.g5  g1.g1.g6  g1.g1.g7  \\\n",
       "0  1.000000  0.750000  0.250000  0.390625  0.312500  0.687500       0.0   \n",
       "1  0.600000  0.800000  1.000000  0.500000  0.000000  0.700000       0.0   \n",
       "2  0.500000  0.500000  0.625000  0.312500  0.375000  0.250000       0.0   \n",
       "3  0.555556  0.777778  0.444444  0.138889  0.555556  0.444444       0.0   \n",
       "4  0.875000  0.500000  0.625000  0.156250  0.500000  0.375000       0.0   \n",
       "\n",
       "   g1.g2.g1  g1.g2.g2  g1.g2.g3  ...  g7.g6.g5  g7.g6.g6  g7.g6.g7  g7.g7.g1  \\\n",
       "0     0.375  0.437500  0.562500  ...       0.0       0.0       0.0       0.0   \n",
       "1     0.400  0.400000  0.400000  ...       0.0       0.0       0.0       0.0   \n",
       "2     0.750  0.500000  0.500000  ...       0.0       0.0       0.0       0.0   \n",
       "3     1.000  0.555556  0.222222  ...       0.0       0.0       0.0       0.0   \n",
       "4     1.000  0.750000  0.375000  ...       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   g7.g7.g2  g7.g7.g3  g7.g7.g4  g7.g7.g5  g7.g7.g6  g7.g7.g7  \n",
       "0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "1       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "3       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "4       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 343 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = minmax.fit_transform(ctriad_X)\n",
    "X_train = pd.DataFrame(X_train, index  = ctriad_X.index, columns = ctriad_X.columns)\n",
    "y_train = ctriad_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = minmax.fit_transform(ctriad_indX_test)\n",
    "X_test = pd.DataFrame(X_test, index = ctriad_indX_test.index, columns = ctriad_indX_test.columns)\n",
    "y_test = ctriad_indy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection for Sequence with large Attribute > 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_select(X_train, y_train): \n",
    "    \n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from numpy import sort\n",
    "\n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    thresholds = np.sort(xgb.feature_importances_)[::-1]\n",
    "\n",
    "    feature_thresh = pd.DataFrame(columns = ['Thresh', 'n', 'Accuracy'])\n",
    "    columns = list(feature_thresh)\n",
    "    data = []\n",
    "\n",
    "    thresh_limit = 1\n",
    "\n",
    "    for thresh in thresholds:\n",
    "\n",
    "        #to Stop the loop if the threshold no longer improves\n",
    "\n",
    "        if thresh >= thresh_limit:\n",
    "            break\n",
    "\n",
    "        #select features using threshold\n",
    "        selection =  SelectFromModel(xgb, threshold = thresh, prefit = True)\n",
    "        select_X_train = selection.transform(X_train)\n",
    "\n",
    "        #train model\n",
    "        selection_model = XGBClassifier()\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "\n",
    "        #evaluate model\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        predictions = selection_model.predict(select_X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "\n",
    "        #print(\"Thresh = %.3f, n = %d, Accuracy = %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
    "\n",
    "        thresh_limit = thresh\n",
    "\n",
    "        values = [thresh, select_X_train.shape[1], accuracy*100]\n",
    "        zipped = zip(columns, values)\n",
    "        values_dict = dict(zipped)\n",
    "        data.append(values_dict)\n",
    "\n",
    "    feature_thresh = feature_thresh.append(data, True)\n",
    "\n",
    "    best_accuracy = feature_thresh[feature_thresh['Accuracy'] == feature_thresh['Accuracy'].max()]\n",
    "    best_threshold = best_accuracy.Thresh.min()\n",
    "\n",
    "    # transform training data based on the selected feature importances\n",
    "    best_thresh = SelectFromModel(xgb, threshold = best_threshold, prefit = True)\n",
    "    \n",
    "    X_train_best = pd.DataFrame(best_thresh.transform(X_train))\n",
    "    X_test_best = pd.DataFrame(best_thresh.transform(X_test))\n",
    "\n",
    "    return X_train_best, X_test_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if X_train.shape[1] > 100:\n",
    "#    X_train, X_test = feat_select(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    #level0.append(('lr', LogisticRegression()))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    #level0.append(('cart', DecisionTreeClassifier()))\n",
    "    level0.append(('lsvm', LinearSVC()))\n",
    "    level0.append(('svm', SVC()))\n",
    "    level0.append(('et', ExtraTreesClassifier()))\n",
    "    level0.append(('rf', RandomForestClassifier()))\n",
    "    #level0.append(('bayes', GaussianNB()))\n",
    "    level0.append(('xgb', XGBClassifier()))\n",
    "    \n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    #models['lr'] = LogisticRegression()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "    #models['cart'] = DecisionTreeClassifier()\n",
    "    models['lsvm'] = LinearSVC(C=15.0, dual=False, \n",
    "                               loss='squared_hinge', \n",
    "                               penalty='l2', tol=0.01)\n",
    "    models['et'] = ExtraTreesClassifier(bootstrap=False, \n",
    "                     criterion = 'entropy', \n",
    "                     max_features=0.35000000000000003, \n",
    "                     min_samples_leaf=18, \n",
    "                     min_samples_split=9, \n",
    "                     n_estimators=100)\n",
    "    \n",
    "    models['rf'] = RandomForestClassifier()\n",
    "    models['svm'] = SVC()\n",
    "    #models['bayes'] = GaussianNB()\n",
    "    models['xgb'] = XGBClassifier()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, \n",
    "                             scoring='roc_auc', \n",
    "                             cv=cv, \n",
    "                             n_jobs=-1, \n",
    "                             error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">knn 0.878 (0.047)\n",
      ">lsvm 0.921 (0.034)\n",
      ">et 0.894 (0.043)\n",
      ">rf 0.904 (0.046)\n",
      ">svm 0.933 (0.036)\n",
      ">xgb 0.920 (0.037)\n",
      ">stacking 0.935 (0.030)\n"
     ]
    }
   ],
   "source": [
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X_train, y_train)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">knn 0.7353\n",
      ">lsvm 0.7206\n",
      ">et 0.5294\n",
      ">rf 0.5147\n",
      ">svm 0.6176\n",
      ">xgb 0.5882\n",
      ">stacking 0.6471\n"
     ]
    }
   ],
   "source": [
    "# Result on Test Set\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    mod = model.fit(X_train, y_train)\n",
    "    y_pred = mod.predict(X_test)\n",
    "    \n",
    "    fpr,tpr,thresholds = metrics.roc_curve(y_test, \n",
    "                                           y_pred, \n",
    "                                           pos_label = 1)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    \n",
    "    results.append(auc)\n",
    "    names.append(name)\n",
    "    print('>%s %.4f' % (name, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
